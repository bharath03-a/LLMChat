{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "import time\n",
    "import os\n",
    "from typing import TypedDict, List, Dict, Any, Optional, Union\n",
    "from IPython.display import Image, display\n",
    "import weaviate\n",
    "from weaviate.auth import Auth\n",
    "import weaviate.classes as wvc\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_weaviate.vectorstores import WeaviateVectorStore\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Importing necessary libraries\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from tavily import TavilyClient\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentProcessor:\n",
    "    \"\"\"Process legal documents and create vector store\"\"\"\n",
    "    \n",
    "    def __init__(self, documents_dir: str = \"./notes\"):\n",
    "        self.documents_dir = documents_dir\n",
    "        self.weaviate_url = os.environ.get(\"WEAVIATE_URL\")\n",
    "        self.weaviate_api_key = os.environ.get(\"WEAVIATE_API_KEY\")\n",
    "        self.embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "        )\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200\n",
    "        )\n",
    "        \n",
    "    def load_documents(self) -> List[Any]:\n",
    "        \"\"\"Load documents from the directory\"\"\"\n",
    "        try:\n",
    "            loader = DirectoryLoader(\n",
    "                self.documents_dir,\n",
    "                glob=\"**/*.pdf\",\n",
    "                loader_cls=PyPDFLoader\n",
    "            )\n",
    "            documents = loader.load()\n",
    "            print(f\"Loaded {len(documents)} documents.\")\n",
    "            return documents\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading documents: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def process_documents(self) -> List[Any]:\n",
    "        \"\"\"Split documents into chunks\"\"\"\n",
    "        documents = self.load_documents()\n",
    "        chunks = self.text_splitter.split_documents(documents)\n",
    "        print(f\"Split into {len(chunks)} chunks\")\n",
    "        return chunks\n",
    "    \n",
    "    def create_vector_store(self) -> WeaviateVectorStore:\n",
    "        \"\"\"Create and populate vector store with documents using LangChain's WeaviateVectorStore\"\"\"\n",
    "        \n",
    "        client = weaviate.connect_to_weaviate_cloud(\n",
    "            cluster_url=self.weaviate_url,\n",
    "            auth_credentials=Auth.api_key(self.weaviate_api_key),\n",
    "        )\n",
    "        \n",
    "        chunks = self.process_documents()\n",
    "        \n",
    "        if client.collections.exists(\"LegalDocuments\"):\n",
    "            client.collections.delete(\"LegalDocuments\")\n",
    "        \n",
    "        vector_store = WeaviateVectorStore.from_documents(\n",
    "            documents=chunks,\n",
    "            embedding=self.embeddings,\n",
    "            client=client,\n",
    "            index_name=\"LegalDocuments\", \n",
    "            text_key=\"content\",\n",
    "            by_text=False\n",
    "        )\n",
    "        \n",
    "        print(f\"Successfully imported {len(chunks)} chunks into Weaviate\")\n",
    "        return vector_store\n",
    "    \n",
    "    def query_store(self, query: str, vector_store: WeaviateVectorStore, k: int = 5):\n",
    "        \"\"\"Query the vector store for similar documents\"\"\"\n",
    "        docs = vector_store.similarity_search(query, k=k)\n",
    "        return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processor = DocumentProcessor(documents_dir=\"../streamlit_app/notes/\")\n",
    "# vector_store = processor.create_vector_store()\n",
    "\n",
    "# results = processor.query_store(\"contract breach provisions\", vector_store)\n",
    "\n",
    "# for i, doc in enumerate(results):\n",
    "#     print(f\"\\nDocument {i+1}:\")\n",
    "#     print(f\"Source: {doc.metadata.get('source', 'Unknown')}, Page: {doc.metadata.get('page', 'Unknown')}\")\n",
    "#     print(doc.page_content[:150] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedAgentState(TypedDict):\n",
    "    \"\"\"Enhanced state management for the Legal AI Assistant\"\"\"\n",
    "    input: Any\n",
    "    input_type: str\n",
    "    processed_input: Optional[Dict[str, Any]]\n",
    "    query_details: Optional[Dict[str, Any]]\n",
    "    document_search_results: Optional[List[Dict[str, Any]]]\n",
    "    document_search_sufficient: Optional[bool]\n",
    "    web_search_results: Optional[List[Dict[str, Any]]]\n",
    "    web_search_sufficient: Optional[bool]\n",
    "    need_additional_search: Optional[bool]\n",
    "    final_response: Optional[str]\n",
    "    references: Optional[List[str]]\n",
    "    conversation_history: List[Union[HumanMessage, AIMessage]]\n",
    "\n",
    "def determine_search_sufficiency(state: EnhancedAgentState, search_type: str, threshold: float = 7.0) -> Dict[str, Any]:\n",
    "    \"\"\"Determine if search results are sufficient based on relevance score\"\"\"\n",
    "    if search_type == \"document\":\n",
    "        evaluation = state.get(\"document_search_evaluation\", {})\n",
    "        relevance_score = evaluation.get(\"Relevance Score\", 0)\n",
    "        sufficient = relevance_score >= threshold\n",
    "        \n",
    "        return {\n",
    "            \"document_search_sufficient\": sufficient,\n",
    "            \"need_additional_search\": not sufficient\n",
    "        }\n",
    "    elif search_type == \"web\":\n",
    "        evaluation = state.get(\"web_search_evaluation\", {})\n",
    "        relevance_score = evaluation.get(\"Relevance Score\", 0)\n",
    "        sufficient = relevance_score >= threshold\n",
    "        \n",
    "        return {\n",
    "            \"web_search_sufficient\": sufficient,\n",
    "            \"need_additional_search\": state.get(\"need_additional_search\", True) and not sufficient\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported search type: {search_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, Any, Optional, List, Union\n",
    "import tempfile\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from io import BytesIO\n",
    "\n",
    "class MultimodalInputHandler:\n",
    "    \"\"\"Handle different types of inputs (text, image, file)\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Configure pytesseract path if needed\n",
    "        # pytesseract.pytesseract.tesseract_cmd = r'<path_to_tesseract_executable>'\n",
    "        pass\n",
    "    \n",
    "    def process_text(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Process plain text input\"\"\"\n",
    "        return {\n",
    "            \"type\": \"text\",\n",
    "            \"content\": text,\n",
    "            \"metadata\": {}\n",
    "        }\n",
    "    \n",
    "    def process_image(self, image_data: Union[str, bytes, Image.Image]) -> Dict[str, Any]:\n",
    "        \"\"\"Process image input using OCR\"\"\"\n",
    "        if isinstance(image_data, str):\n",
    "            # Assuming image_data is a file path\n",
    "            image = Image.open(image_data)\n",
    "        elif isinstance(image_data, bytes):\n",
    "            image = Image.open(BytesIO(image_data))\n",
    "        else:\n",
    "            image = image_data\n",
    "            \n",
    "        # Extract text from image using OCR\n",
    "        extracted_text = pytesseract.image_to_string(image)\n",
    "        \n",
    "        return {\n",
    "            \"type\": \"image\",\n",
    "            \"content\": extracted_text,\n",
    "            \"metadata\": {\n",
    "                \"original_format\": \"image\",\n",
    "                \"image_size\": image.size,\n",
    "                \"image_mode\": image.mode\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def process_pdf(self, pdf_data: Union[str, bytes]) -> Dict[str, Any]:\n",
    "        \"\"\"Process PDF input\"\"\"\n",
    "        if isinstance(pdf_data, bytes):\n",
    "            # Create a temporary file\n",
    "            with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as temp_file:\n",
    "                temp_file.write(pdf_data)\n",
    "                temp_file_path = temp_file.name\n",
    "                \n",
    "            try:\n",
    "                loader = PyPDFLoader(temp_file_path)\n",
    "                documents = loader.load()\n",
    "                \n",
    "                # Extract text from all pages\n",
    "                full_text = \"\\n\".join(doc.page_content for doc in documents)\n",
    "                \n",
    "                return {\n",
    "                    \"type\": \"pdf\",\n",
    "                    \"content\": full_text,\n",
    "                    \"metadata\": {\n",
    "                        \"original_format\": \"pdf\",\n",
    "                        \"page_count\": len(documents),\n",
    "                        \"documents\": documents\n",
    "                    }\n",
    "                }\n",
    "            finally:\n",
    "                # Remove temporary file\n",
    "                os.unlink(temp_file_path)\n",
    "        else:\n",
    "            # Assuming pdf_data is a file path\n",
    "            loader = PyPDFLoader(pdf_data)\n",
    "            documents = loader.load()\n",
    "            \n",
    "            # Extract text from all pages\n",
    "            full_text = \"\\n\".join(doc.page_content for doc in documents)\n",
    "            \n",
    "            return {\n",
    "                \"type\": \"pdf\",\n",
    "                \"content\": full_text,\n",
    "                \"metadata\": {\n",
    "                    \"original_format\": \"pdf\",\n",
    "                    \"page_count\": len(documents),\n",
    "                    \"documents\": documents\n",
    "                }\n",
    "            }\n",
    "    \n",
    "    def process_input(self, input_data: Any, input_type: str) -> Dict[str, Any]:\n",
    "        \"\"\"Process any input based on its type\"\"\"\n",
    "        if input_type == \"text\":\n",
    "            return self.process_text(input_data)\n",
    "        elif input_type == \"image\":\n",
    "            return self.process_image(input_data)\n",
    "        elif input_type == \"pdf\":\n",
    "            return self.process_pdf(input_data)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported input type: {input_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting up AI Agent workflow\n",
    "class LegalAIAssistant:\n",
    "    def __init__(self, weaviate_url: Optional[str] = None):\n",
    "        self.llm = ChatGroq(\n",
    "            model=\"llama3-70b-8192\",\n",
    "            temperature=0.6,\n",
    "            api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "        )\n",
    "        \n",
    "        self.tavily_client = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
    "    \n",
    "        self.document_processor = DocumentProcessor(documents_dir=\"../streamlit_app/notes/\")\n",
    "        self.vector_store = self.document_processor.create_vector_store()\n",
    "\n",
    "        self.input_handler = MultimodalInputHandler()\n",
    "        \n",
    "        self.query_understanding_system = \"\"\"You are an expert legal AI assistant specializing in understanding complex legal queries.\n",
    "        Your task is to analyze the user's input and break it down into components that will guide a comprehensive legal search and response.\n",
    "        Pay special attention to:\n",
    "        1. Identifying the core legal issue or question\n",
    "        2. Determining relevant jurisdictions\n",
    "        3. Identifying specific legal domains (criminal, civil, corporate, etc.)\n",
    "        4. Extracting potential subqueries that need separate investigation\n",
    "        5. Identifying any time-sensitive elements\n",
    "        \n",
    "        Format your analysis as a structured JSON object.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.document_evaluation_system = \"\"\"You are an expert legal document analyst.\n",
    "        Your task is to evaluate search results from a legal document database and determine if they adequately address the user's query.\n",
    "        Consider:\n",
    "        1. Relevance of the documents to the specific legal question\n",
    "        2. Comprehensiveness of the information provided\n",
    "        3. Accuracy and authority of the sources\n",
    "        4. Whether the information is complete or requires additional context\n",
    "        \n",
    "        Assign a relevance score (0-10) and explain your reasoning.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.web_evaluation_system = \"\"\"You are an expert legal research analyst.\n",
    "        Your task is to evaluate web search results and determine if they adequately address aspects of the user's legal query.\n",
    "        Consider:\n",
    "        1. Credibility of the sources (government sites, law firms, legal journals)\n",
    "        2. Relevance to the specific legal question\n",
    "        3. Currency of the information (especially important for evolving legal topics)\n",
    "        4. Whether the results complement the document search results\n",
    "        \n",
    "        Assign a relevance score (0-10) and explain your reasoning.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.final_response_system = \"\"\"You are a comprehensive legal AI assistant tasked with providing accurate, nuanced, and helpful legal information.\n",
    "        When generating your response:\n",
    "        1. Focus on factual legal information and procedural guidance\n",
    "        2. Clearly distinguish between established law, legal interpretation, and practical advice\n",
    "        3. Include relevant citations and references to legal statutes, cases, or authorities\n",
    "        4. Provide balanced perspectives where legal interpretations differ\n",
    "        5. Clarify any jurisdictional limitations to your advice\n",
    "        6. Include appropriate disclaimers about not providing legal advice\n",
    "        \n",
    "        Structure your response in a clear, logical format with headings where appropriate.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Initialize prompts\n",
    "        self._initialize_prompts()\n",
    "\n",
    "        self.visualize_workflow(\"./img/workflow.png\")\n",
    "    \n",
    "    def _initialize_prompts(self):\n",
    "        \"\"\"Initialize all prompts used by the assistant\"\"\"\n",
    "        # Query Understanding Prompt\n",
    "        self.query_understanding_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", self.query_understanding_system),\n",
    "            (\"human\", \"\"\"Analyze the following legal query and break it down into its key components:\n",
    "\n",
    "            {processed_input}\n",
    "\n",
    "            Return a structured JSON with these fields:\n",
    "            - core_legal_issue: The main legal question or problem\n",
    "            - jurisdiction: Relevant legal jurisdiction(s) if specified or can be inferred\n",
    "            - legal_domains: List of relevant legal areas (e.g., criminal, civil, property)\n",
    "            - subqueries: List of related questions that might need separate investigation\n",
    "            - time_sensitivity: Any urgent aspects of the query\n",
    "            - key_terms: Important legal terms mentioned or implied in the query\n",
    "             \n",
    "            1. **First, output JSON only** without any inline comments.\n",
    "            2. **After the JSON, provide explanations** in natural language.\n",
    "            \"\"\")\n",
    "        ])\n",
    "        \n",
    "        # Document Search Evaluation Prompt\n",
    "        self.document_evaluation_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", self.document_evaluation_system),\n",
    "            (\"human\", \"\"\"Evaluate these document search results for the legal query:\n",
    "\n",
    "            Query Details: {query_details}\n",
    "\n",
    "            Document Search Results:\n",
    "            {document_search_results}\n",
    "\n",
    "            Provide a JSON response with these fields:\n",
    "            - Relevance Score: (0-10)\n",
    "            - Key Matching Sections: List of sections most relevant to the query\n",
    "            - Information Gaps: Legal aspects of the query not covered by these documents\n",
    "            - Confidence Assessment: Your confidence in the documents answering the query correctly\n",
    "            \"\"\")\n",
    "        ])\n",
    "        \n",
    "        # Web Search Evaluation Prompt\n",
    "        self.web_evaluation_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", self.web_evaluation_system),\n",
    "            (\"human\", \"\"\"Evaluate these web search results for the legal query:\n",
    "\n",
    "            Query Details: {query_details}\n",
    "\n",
    "            Web Search Results:\n",
    "            {web_search_results}\n",
    "\n",
    "            Provide a JSON response with these fields:\n",
    "            - Relevance Score: (0-10)\n",
    "            - Key Insights: Main legal information found in the results\n",
    "            - Source Credibility: Assessment of the credibility of the sources\n",
    "            - Information Gaps: Aspects of the query not adequately addressed\n",
    "            - Comparison to Document Results: How these results complement the document search\n",
    "            \"\"\")\n",
    "        ])\n",
    "        \n",
    "        # Final Response Generation Prompt\n",
    "        self.final_response_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", self.final_response_system),\n",
    "            (\"human\", \"\"\"Generate a comprehensive legal response based on the following:\n",
    "\n",
    "            Original Query: {processed_input}\n",
    "            Query Analysis: {query_details}\n",
    "            Document Search Results: {document_search_results}\n",
    "            Web Search Results: {web_search_results}\n",
    "\n",
    "            Your response should include:\n",
    "            1. A clear explanation of the legal concepts and principles\n",
    "            2. Applicable laws, regulations, or precedents\n",
    "            3. Practical guidance on how to proceed\n",
    "            4. Any necessary disclaimers about jurisdictional limitations\n",
    "            5. References to sources used\n",
    "\n",
    "            Remember to remain balanced, factual, and helpful while acknowledging legal complexities.\n",
    "            \"\"\")\n",
    "        ])\n",
    "    \n",
    "    def process_input_node(self, state: EnhancedAgentState) -> Dict[str, Any]:\n",
    "        \"\"\"Process the input based on its type\"\"\"\n",
    "        processed_input = self.input_handler.process_input(\n",
    "            state['input'], \n",
    "            state['input_type']\n",
    "        )\n",
    "\n",
    "        if 'conversation_history' not in state:\n",
    "            state['conversation_history'] = []\n",
    "        \n",
    "        return {\"processed_input\": processed_input}\n",
    "    \n",
    "    def understand_query_node(self, state: EnhancedAgentState) -> Dict[str, Any]:\n",
    "        \"\"\"Node for understanding the query\"\"\"\n",
    "        chain = self.query_understanding_prompt | self.llm | JsonOutputParser()\n",
    "\n",
    "        human_message = HumanMessage(\n",
    "            content=state['processed_input']['content'],\n",
    "            additional_kwargs={\"timestamp\": time.time()}\n",
    "        )\n",
    "        state['conversation_history'].append(human_message)\n",
    "        max_history_size = 10 \n",
    "        if len(state['conversation_history']) > max_history_size:\n",
    "            state['conversation_history'] = state['conversation_history'][-max_history_size:]\n",
    "\n",
    "        recent_context = state['conversation_history'][-3:]\n",
    "\n",
    "        context_enhanced_query = state['processed_input']['content']\n",
    "        query_details = chain.invoke({\"processed_input\": context_enhanced_query})\n",
    "        \n",
    "        return {\n",
    "            \"query_details\": query_details,\n",
    "            \"conversation_history\": state['conversation_history']\n",
    "        }\n",
    "\n",
    "    def document_search_node(self, state: EnhancedAgentState) -> Dict[str, Any]:\n",
    "        \"\"\"Node for searching legal documents\"\"\"\n",
    "        # Extract key terms from query details\n",
    "        key_terms = state['query_details'].get('key_terms', [])\n",
    "        core_issue = state['query_details'].get('core_legal_issue', '')\n",
    "        \n",
    "        # Combine terms for search\n",
    "        search_query = f\"{core_issue} {' '.join(key_terms)}\"\n",
    "        \n",
    "        # Use vector store to search documents\n",
    "        search_results = self.vector_store.similarity_search_with_score(\n",
    "            query=search_query,\n",
    "            k=5,\n",
    "        )\n",
    "        \n",
    "        # Format results for the LLM\n",
    "        document_search_results = [\n",
    "            {\n",
    "                \"source\": result[0].metadata.get('source', 'Unknown'),\n",
    "                \"page\": result[0].metadata.get('page', 0),\n",
    "                \"relevance_score\": result[1],\n",
    "                \"content\": result[0].page_content\n",
    "            }\n",
    "            for result in search_results\n",
    "        ]\n",
    "        \n",
    "        # Evaluate search results\n",
    "        chain = self.document_evaluation_prompt | self.llm | JsonOutputParser()\n",
    "        document_evaluation = chain.invoke({\n",
    "            \"query_details\": state['query_details'],\n",
    "            \"document_search_results\": document_search_results\n",
    "        })\n",
    "        \n",
    "        return {\n",
    "            \"document_search_results\": document_search_results,\n",
    "            \"document_search_evaluation\": document_evaluation\n",
    "        }\n",
    "\n",
    "    def evaluate_doc_search_node(self, state: EnhancedAgentState) -> Dict[str, Any]:\n",
    "        \"\"\"Node for evaluating document search results and deciding next steps\"\"\"\n",
    "        return determine_search_sufficiency(state, \"document\")\n",
    "\n",
    "    def web_search_node(self, state: EnhancedAgentState) -> Dict[str, Any]:\n",
    "        \"\"\"Node for web searching\"\"\"\n",
    "        # Use the core legal issue and key terms for search\n",
    "        core_issue = state['query_details'].get('core_legal_issue', '')\n",
    "        jurisdiction = state['query_details'].get('jurisdiction', '')\n",
    "        \n",
    "        # Construct a more specific query for web search\n",
    "        web_query = f\"{core_issue} legal {jurisdiction}\"\n",
    "        \n",
    "        web_search_results = self.tavily_client.search(\n",
    "            query=web_query, \n",
    "            max_results=5,\n",
    "            search_depth=\"advanced\"\n",
    "        )\n",
    "        \n",
    "        # Evaluate web search results\n",
    "        chain = self.web_evaluation_prompt | self.llm | JsonOutputParser()\n",
    "        web_search_evaluation = chain.invoke({\n",
    "            \"query_details\": state['query_details'],\n",
    "            \"web_search_results\": web_search_results['results']\n",
    "        })\n",
    "        \n",
    "        return {\n",
    "            \"web_search_results\": web_search_results['results'],\n",
    "            \"web_search_evaluation\": web_search_evaluation\n",
    "        }\n",
    "\n",
    "    def evaluate_web_search_node(self, state: EnhancedAgentState) -> Dict[str, Any]:\n",
    "        \"\"\"Node for evaluating web search results and deciding next steps\"\"\"\n",
    "        return determine_search_sufficiency(state, \"web\")\n",
    "\n",
    "    def generate_final_response_node(self, state: EnhancedAgentState) -> Dict[str, Any]:\n",
    "        \"\"\"Node for generating final comprehensive response\"\"\"\n",
    "        recent_conversation = state['conversation_history'][-5:]\n",
    "\n",
    "        chain = self.final_response_prompt | self.llm\n",
    "        final_response = chain.invoke({\n",
    "            \"processed_input\": state['processed_input']['content'],\n",
    "            \"query_details\": state['query_details'],\n",
    "            \"document_search_results\": state['document_search_results'],\n",
    "            \"web_search_results\": state['web_search_results'],\n",
    "            \"recent_conversation\": recent_conversation\n",
    "        })\n",
    "\n",
    "        ai_message = AIMessage(\n",
    "            content=final_response.content,\n",
    "            additional_kwargs={\"timestamp\": time.time()}\n",
    "        )\n",
    "        state['conversation_history'].append(ai_message)\n",
    "        \n",
    "        # Collect references\n",
    "        references = []\n",
    "        \n",
    "        # Add document references\n",
    "        for doc in state.get('document_search_results', []):\n",
    "            source = doc.get('source', '')\n",
    "            page = doc.get('page', '')\n",
    "            if source and source not in references:\n",
    "                references.append(f\"{source} (Page {page})\")\n",
    "        \n",
    "        # Add web references\n",
    "        for result in state.get('web_search_results', []):\n",
    "            url = result.get('url', '')\n",
    "            if url and url not in references:\n",
    "                references.append(url)\n",
    "        \n",
    "        return {\n",
    "            \"final_response\": final_response.content,\n",
    "            \"references\": references,\n",
    "            \"conversation_history\": state['conversation_history']\n",
    "        }\n",
    "    \n",
    "    def additional_search_node(self, state: EnhancedAgentState) -> Dict[str, Any]:\n",
    "        \"\"\"Node for performing additional searches when needed\"\"\"\n",
    "        # Identify information gaps from evaluations\n",
    "        doc_eval = state.get('document_search_evaluation', {})\n",
    "        web_eval = state.get('web_search_evaluation', {})\n",
    "        \n",
    "        info_gaps_doc = doc_eval.get('Information Gaps', [])\n",
    "        info_gaps_web = web_eval.get('Information Gaps', [])\n",
    "        \n",
    "        # Combine information gaps\n",
    "        all_gaps = info_gaps_doc + info_gaps_web\n",
    "        \n",
    "        # Use Tavily for specialized search on the gaps\n",
    "        additional_results = []\n",
    "        for gap in all_gaps:\n",
    "            if isinstance(gap, str) and gap.strip():\n",
    "                try:\n",
    "                    gap_results = self.tavily_client.search(\n",
    "                        query=f\"{gap} legal information {state['query_details'].get('jurisdiction', '')}\",\n",
    "                        max_results=2,\n",
    "                        search_depth=\"advanced\"\n",
    "                    )\n",
    "                    additional_results.extend(gap_results['results'])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in additional search: {e}\")\n",
    "        \n",
    "        # Combine with existing web search results\n",
    "        current_web_results = state.get('web_search_results', [])\n",
    "        combined_results = current_web_results + additional_results\n",
    "        \n",
    "        # Remove duplicates by URL\n",
    "        seen_urls = set()\n",
    "        unique_results = []\n",
    "        for result in combined_results:\n",
    "            url = result.get('url', '')\n",
    "            if url and url not in seen_urls:\n",
    "                seen_urls.add(url)\n",
    "                unique_results.append(result)\n",
    "        \n",
    "        return {\n",
    "            \"web_search_results\": unique_results[:8],  # Limit to top 8 results\n",
    "            \"need_additional_search\": False  # Reset flag\n",
    "        }\n",
    "    \n",
    "    def should_perform_additional_search(self, state: EnhancedAgentState) -> str:\n",
    "        \"\"\"Decision node to determine if additional search is needed\"\"\"\n",
    "        if state.get(\"need_additional_search\", False):\n",
    "            return \"additional_search\"\n",
    "        return \"generate_response\"\n",
    "    \n",
    "    def build_workflow(self):\n",
    "        \"\"\"Construct the agentic workflow using LangGraph with decision points\"\"\"\n",
    "        workflow = StateGraph(EnhancedAgentState)\n",
    "        \n",
    "        # Add all nodes\n",
    "        workflow.add_node(\"process_input\", self.process_input_node)\n",
    "        workflow.add_node(\"understand_query\", self.understand_query_node)\n",
    "        workflow.add_node(\"document_search\", self.document_search_node)\n",
    "        workflow.add_node(\"evaluate_doc_search\", self.evaluate_doc_search_node)\n",
    "        workflow.add_node(\"web_search\", self.web_search_node)\n",
    "        workflow.add_node(\"evaluate_web_search\", self.evaluate_web_search_node)\n",
    "        workflow.add_node(\"additional_search\", self.additional_search_node)\n",
    "        workflow.add_node(\"generate_response\", self.generate_final_response_node)\n",
    "        \n",
    "        # Define workflow edges with decision points\n",
    "        workflow.set_entry_point(\"process_input\")\n",
    "        workflow.add_edge(\"process_input\", \"understand_query\")\n",
    "        workflow.add_edge(\"understand_query\", \"document_search\")\n",
    "        workflow.add_edge(\"document_search\", \"evaluate_doc_search\")\n",
    "        \n",
    "        # Decision after document search\n",
    "        workflow.add_conditional_edges(\n",
    "            \"evaluate_doc_search\",\n",
    "            self.should_perform_additional_search,\n",
    "            {\n",
    "                \"additional_search\": \"additional_search\",\n",
    "                \"generate_response\": \"web_search\"\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        workflow.add_edge(\"web_search\", \"evaluate_web_search\")\n",
    "        \n",
    "        # Decision after web search\n",
    "        workflow.add_conditional_edges(\n",
    "            \"evaluate_web_search\",\n",
    "            self.should_perform_additional_search,\n",
    "            {\n",
    "                \"additional_search\": \"additional_search\",\n",
    "                \"generate_response\": \"generate_response\"\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        workflow.add_edge(\"additional_search\", \"generate_response\")\n",
    "        workflow.set_finish_point(\"generate_response\")\n",
    "        \n",
    "        return workflow.compile()\n",
    "    \n",
    "    def visualize_workflow(self, graph: StateGraph):\n",
    "        \"\"\"Visualize the LangGraph workflow with decision points and save it to a file.\"\"\"\n",
    "        \n",
    "        try:\n",
    "            img = Image(graph.get_graph().draw_mermaid_png())\n",
    "            with open(\"mermaid_graph.png\", \"wb\") as f:\n",
    "                f.write(img.data)\n",
    "            print(\"Image saved as mermaid_graph.png\")\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "\n",
    "    async def process_query(self, query: Any, input_type: str = \"text\", conversation_history=None):\n",
    "        \"\"\"Async method to process user query with any input type\"\"\"\n",
    "        workflow = self.build_workflow()\n",
    "        initial_state = {\n",
    "            \"input\": query,\n",
    "            \"input_type\": input_type,\n",
    "            \"conversation_history\": conversation_history or []\n",
    "        }\n",
    "        \n",
    "        result = await workflow.ainvoke(initial_state)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1465 documents.\n",
      "Split into 5892 chunks\n",
      "Successfully imported 5892 chunks into Weaviate\n",
      "Error: 'str' object has no attribute 'get_graph'\n"
     ]
    }
   ],
   "source": [
    "assistant = LegalAIAssistant()\n",
    "query = \"What are the legal implications of breaking a non-compete agreement in California?\"\n",
    "\n",
    "result = await assistant.process_query(query, \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_history = result.get(\"conversation_history\", [])\n",
    "\n",
    "follow_up_query = \"What if I signed the agreement in Nevada but now work in California?\"\n",
    "\n",
    "\n",
    "follow_up_result = await assistant.process_query(\n",
    "    follow_up_query, \n",
    "    \"text\",\n",
    "    conversation_history=conversation_history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_conversation_history = follow_up_result.get(\"conversation_history\", [])\n",
    "\n",
    "third_query = \"Can my former employer sue me for damages?\"\n",
    "third_result = await assistant.process_query(\n",
    "    third_query,\n",
    "    \"text\",\n",
    "    conversation_history=updated_conversation_history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What are the legal implications of breaking a non-compete agreement in California?\n",
      "\n",
      "Assistant: **Legal Implications of Breaking a Non-Compete Agreement in California**\n",
      "\n",
      "**Introduction**\n",
      "\n",
      "A non-compete agreement, also known as a covenant not to compete, is a contractual provision that restricts an individual's ability to engage in a particular profession, trade, or business within a specific geographic area for a certain period of time. Breaking a non-compete agreement can have significant legal implications, including potential lawsuits, damages, and injunctions. This response will provide an overview of the legal implications of breaking a non-compete agreement in California, including what constitutes a breach, available remedies, and the enforceability of non-compete agreements in California.\n",
      "\n",
      "**What Constitutes a Breach of a Non-Compete Agreement?**\n",
      "\n",
      "A breach of a non-compete agreement occurs when an individual or entity fails to comply with the agreed-upon restrictions, such as working for a competitor, soliciting customers, or disclosing confidential information. To establish a breach, the party alleging the breach must show that the agreement was valid, that the defendant had knowledge of the agreement, and that the defendant engaged in conduct that violated the agreement's terms. (See, e.g., _Edwards v. Arthur Andersen LLP_ (2008) 44 Cal.4th 937, 946.)\n",
      "\n",
      "**Remedies for a Breached Non-Compete Agreement in California**\n",
      "\n",
      "If a court finds that a non-compete agreement has been breached, the following remedies may be available:\n",
      "\n",
      "1. **Injunction**: A court may grant an injunction to prevent further breaches of the agreement. (See, e.g., _Trade Secrets cases_ (2008) 161 Cal.App.4th 1009, 1021.)\n",
      "2. **Damages**: The non-breaching party may be entitled to damages, including lost profits, lost business opportunities, and other economic losses. (See, e.g., _Moss Bros. v. Moss_ (1989) 207 Cal.App.3d 1089, 1097.)\n",
      "3. **Specific Performance**: In some cases, a court may order specific performance, requiring the breaching party to comply with the agreement's terms.\n",
      "\n",
      "**Enforceability of Non-Compete Agreements in California**\n",
      "\n",
      "California law generally disfavors non-compete agreements, and they are only enforceable in limited circumstances. Under California Business and Professions Code section 16600, a non-compete agreement is void unless it falls within one of the exceptions specified in the statute, such as a sale of a business or dissolution of a partnership.\n",
      "\n",
      "In _Edwards v. Arthur Andersen LLP_ (2008) 44 Cal.4th 937, the California Supreme Court held that a non-compete agreement was unenforceable because it was overly broad and did not fall within one of the statutory exceptions.\n",
      "\n",
      "**Practical Guidance**\n",
      "\n",
      "If you are considering entering into a non-compete agreement in California, it is essential to:\n",
      "\n",
      "1. **Carefully review the agreement**: Ensure that you understand the terms of the agreement and the restrictions it imposes.\n",
      "2. **Seek legal counsel**: Consult with an attorney to ensure that the agreement is enforceable and that you are not waiving any rights.\n",
      "3. **Consider alternative restrictions**: Instead of a non-compete agreement, consider using non-disclosure agreements or non-solicitation agreements, which may be more enforceable in California.\n",
      "\n",
      "**Disclaimer**\n",
      "\n",
      "This response is not intended to provide legal advice, and you should consult with an attorney licensed in California to discuss your specific situation. The laws and regulations governing non-compete agreements are complex and subject to change, and this response is for informational purposes only.\n",
      "\n",
      "**Sources**\n",
      "\n",
      "* California Business and Professions Code section 16600\n",
      "* _Edwards v. Arthur Andersen LLP_ (2008) 44 Cal.4th 937\n",
      "* _Trade Secrets cases_ (2008) 161 Cal.App.4th 1009\n",
      "* _Moss Bros. v. Moss_ (1989) 207 Cal.App.3d 1089\n",
      "\n",
      "User: What if I signed the agreement in Nevada but now work in California?\n",
      "\n",
      "Assistant: **Applicability of Contract Terms Across State Lines**\n",
      "\n",
      "**Legal Concept:** A contract signed in one state (Nevada) may have implications when working in another state (California). This raises questions about the governing law, contract validity, and potential superseding laws or regulations in California.\n",
      "\n",
      "**Governing Law:**\n",
      "The governing law of a contract is typically determined by the contract itself, which may specify the applicable law. In the absence of such a provision, the court will apply the law of the state with the most significant connection to the contract. (Restatement (Second) of Conflict of Laws ยง 187)\n",
      "\n",
      "**Contract Validity:**\n",
      "A contract signed in Nevada is generally valid and enforceable in California, unless it violates California law or public policy. However, California law may supersede the contract terms if they conflict with California statutes or regulations.\n",
      "\n",
      "**California Laws and Regulations:**\n",
      "California has its own set of laws and regulations that may impact the contract. For example, California Labor Code ยง 925 prohibits employers from requiring employees to adjudicate claims outside of California. If the contract contains a forum selection clause or choice of law provision that conflicts with California law, it may be deemed invalid.\n",
      "\n",
      "**Practical Guidance:**\n",
      "To determine the applicability of the contract terms across state lines:\n",
      "\n",
      "1. Review the contract to see if it specifies the governing law or jurisdiction.\n",
      "2. Identify any California laws or regulations that may supersede the contract terms.\n",
      "3. Consider seeking legal advice from an attorney licensed in California to ensure compliance with California law.\n",
      "\n",
      "**Jurisdictional Limitations:**\n",
      "This response is based on general legal principles and may not be applicable to specific circumstances. It is essential to consult with an attorney licensed in California to obtain legal advice tailored to your situation.\n",
      "\n",
      "**References:**\n",
      "\n",
      "* Restatement (Second) of Conflict of Laws ยง 187\n",
      "* California Labor Code ยง 925\n",
      "* Introduction to Law (PDF), pages 380, 393, 416\n",
      "\n",
      "**Disclaimer:**\n",
      "This response is not intended to provide legal advice. It is essential to consult with an attorney licensed in California to obtain legal advice tailored to your situation.\n",
      "\n",
      "User: Can my former employer sue me for damages?\n",
      "\n",
      "Assistant: **Potential Liability for Damages to Former Employer: A Comprehensive Legal Analysis**\n",
      "\n",
      "**Introduction**\n",
      "\n",
      "As a former employee, you may be concerned about the possibility of being sued by your former employer for damages. This response aims to provide a comprehensive legal analysis of the potential liability for damages to a former employer, including the grounds for a potential lawsuit, applicable contractual or statutory provisions, and the statute of limitations for such a claim.\n",
      "\n",
      "**Grounds for a Potential Lawsuit**\n",
      "\n",
      "A former employer may sue a former employee for damages based on various grounds, including:\n",
      "\n",
      "1. **Breach of Contract**: If you breached the terms of your employment contract, your former employer may claim damages for losses incurred as a result of the breach.\n",
      "2. **Negligence**: If your actions or omissions during your employment caused harm to the employer or its business, your former employer may claim damages for negligence.\n",
      "3. **Vicarious Liability**: If you were acting in the course of your employment when you committed a tort (a civil wrong), your former employer may be liable for damages under the doctrine of vicarious liability.\n",
      "\n",
      "**Applicable Contractual or Statutory Provisions**\n",
      "\n",
      "The following provisions may apply to a potential lawsuit:\n",
      "\n",
      "1. **Employment Contract**: The terms of your employment contract may include provisions related to damages, confidentiality, or non-compete clauses.\n",
      "2. **Employment Legislation**: Relevant employment legislation, such as the Employment Rights Act 1996 (UK), may provide protections for employees and employers.\n",
      "3. **Tort Law**: The law of torts, including negligence and vicarious liability, may apply to claims for damages.\n",
      "\n",
      "**Statute of Limitations**\n",
      "\n",
      "The statute of limitations for a claim for damages against a former employee will depend on the jurisdiction and the specific circumstances of the case. In general, the limitation period for a claim in tort is three years from the date of the alleged wrongdoing (e.g., [Limitation Act 1980, s. 2, UK]).\n",
      "\n",
      "**Practical Guidance**\n",
      "\n",
      "If you are facing a potential lawsuit from your former employer, it is essential to:\n",
      "\n",
      "1. **Seek Legal Advice**: Consult with an experienced employment lawyer to understand your rights and obligations.\n",
      "2. **Review Employment Contract**: Review your employment contract to understand any contractual obligations or limitations.\n",
      "3. **Gather Evidence**: Collect relevant evidence related to your employment and the alleged wrongdoing.\n",
      "\n",
      "**Jurisdictional Limitations**\n",
      "\n",
      "Please note that this response is based on general legal principles and may not be applicable to your specific jurisdiction. It is essential to consult with a qualified lawyer in your jurisdiction to obtain tailored legal advice.\n",
      "\n",
      "**Disclaimer**\n",
      "\n",
      "This response is not intended to provide legal advice. It is a general informational response to the query, and you should not rely on it as legal advice. Consult with a qualified lawyer in your jurisdiction to obtain specific legal guidance.\n",
      "\n",
      "**Sources**\n",
      "\n",
      "* Introduction to Law (pdf)\n",
      "* Limitation Act 1980 (UK)\n",
      "* Employment Rights Act 1996 (UK)\n",
      "\n",
      "Remember, this response is not a substitute for legal advice. If you are facing a potential lawsuit, consult with a qualified lawyer in your jurisdiction to obtain specific legal guidance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def display_conversation(conversation_history):\n",
    "    for message in conversation_history:\n",
    "        speaker = \"User\" if message.type == \"human\" else \"Assistant\"\n",
    "        print(f\"{speaker}: {message.content}\\n\")\n",
    "\n",
    "display_conversation(follow_up_result.get(\"conversation_history\", []))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_Assistant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
